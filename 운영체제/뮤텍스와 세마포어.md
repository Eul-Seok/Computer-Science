# 뮤텍스(Mutex)와 세마포어(Semaphore)

뮤텍스와 세마포어는 운영체제에서 멀티스레드 환경에서의 동기화와 자원 보호를 위한 대표적인 동기화 도구입니다. 둘 다 공유 자원에 대한 접근을 제어하지만, 동작 방식과 사용 목적에서 차이가 있습니다.

> 한마디로, '뮤텍스'와 '세마포어'는 동기화 역할을 수행하는 특정 클래스(Class)나 프로그래밍 도구를 부르는 **이름**이라고 할 수 있습니다. 예를 들어 C++에서는 `std::mutex`나 `std::counting_semaphore` 와 같은 클래스를 코드에 직접 포함(`#include <mutex>`)하여 사용합니다. 프로그래머는 이 클래스의 객체를 생성하고, 그 객체의 함수(메서드)를 호출하는 방식으로 동기화 기능을 구현합니다.

## 뮤텍스 (Mutex)

뮤텍스(Mutex)는 "Mutual Exclusion"의 줄임말로, 상호배제를 보장하는 동기화 객체입니다.

-   하나의 스레드만 특정 <b>임계 구역(Critical Section)</b>에 진입할 수 있도록 제어합니다.
    > **임계 구역**: 여러 스레드가 동시에 접근해서는 안 되는 공유 자원(데이터 또는 코드)의 영역을 의미합니다.
-   다른 스레드들은 해당 구역을 점유한 스레드가 빠져나올 때까지 대기열 구조로 기다리게 됩니다.
-   뮤텍스는 **소유 개념**이 존재하며, 락을 획득한 스레드만 해제할 수 있습니다.
    > **락(Lock)이란?** 공유 자원에 대한 접근 권한을 의미하며, 흔히 '화장실 열쇠'에 비유합니다. 오직 열쇠(락)를 가진 스레드만이 임계 구역에 들어갈 수 있고, 작업이 끝나면 다음 스레드를 위해 열쇠를 반납(해제)해야 합니다. 뮤텍스가 바로 이 락을 구현하는 대표적인 방법입니다.
-   **재진입 가능성(Reentrancy)**: 일부 뮤텍스는 동일한 스레드가 여러 번 락을 획득할 수 있는 재진입(Reentrant) 기능을 제공합니다. 이를 <b>재귀적 뮤텍스(Recursive Mutex)</b>라고 하며, 락을 획득한 횟수만큼 해제해야만 락이 완전히 반환됩니다.
-   데이터 일관성과 **경쟁 조건(Race Condition)** 방지에 효과적입니다.
    > **경쟁 조건**: 두 개 이상의 스레드가 공유 자원에 동시에 접근하고, 그 실행 순서에 따라 결과가 달라질 수 있는 상황을 말합니다.

## 세마포어 (Semaphore)

세마포어(Semaphore)는 공유 자원에 접근할 수 있는 최대 허용 수를 정의하는 신호 기반 동기화 도구입니다.

-   내부적으로 카운터를 유지하며, 자원이 사용될 때마다 카운터가 감소하고, 자원이 반환되면 증가합니다.
-   카운터가 0이 되면 더 이상 접근이 허용되지 않고, 스레드는 대기 상태에 들어갑니다.
-   세마포어는 **소유 개념이 없으며**, 여러 스레드가 동시에 접근할 수 있도록 제어할 수 있습니다.
-   **초기값 설정 전략**: 세마포어의 초기값은 관리하고자 하는 공유 자원의 최대 동시 접근 허용 수에 따라 신중하게 설정해야 합니다. 잘못된 초기값은 시스템의 성능 저하나 자원 낭비를 초래할 수 있습니다.
-   리소스 풀 관리나 제한된 동시 접근 제어에 적합합니다.

### 세마포어 종류
-   **Binary Semaphore**: 값이 0 또는 1만 가질 수 있으며, 뮤텍스와 유사하게 동작합니다.
-   **Counting Semaphore**: 값이 0 이상의 정수일 수 있으며, 여러 개의 자원을 가진 리소스에 대한 접근을 제어하는 데 사용됩니다.

## 주요 차이점 및 구현 방식

-   **구현 방식**: 뮤텍스는 락을 소유한 스레드를 식별하고 스레드의 상태(대기, 실행 등)를 직접 관리해야 하므로 주로 OS 커널 수준에서 구현되며, 이 과정에서 스레드 상태 전환(**Context Switch**)을 유발합니다. 반면, 세마포어는 단순한 카운터로 동작하므로 커널의 개입 없이 사용자 공간(User Space)에서도 비교적 간단히 구현할 수 있습니다.
    > **컨텍스트 스위칭**: 하나의 스레드에서 다른 스레드로 CPU 제어권을 넘겨주는 과정으로, 이 과정에서 비용이 발생합니다.<br>
    > **왜 컨텍스트 스위칭이 발생하나요?** 다른 스레드가 이미 락(Lock)을 점유하고 있을 때, 뒤늦게 락을 요청한 스레드는 무작정 기다릴 수밖에 없습니다. 이때 CPU를 점유한 채로 계속 기다리는 것은 자원 낭비이므로, 운영체제는 해당 스레드를 '대기 상태'로 만들고 CPU를 다른 스레드에게 넘겨줍니다. 바로 이 과정에서 컨텍스트 스위칭이 발생합니다. 즉, CPU 낭비를 막기 위한 운영체제의 효율적인 전략입니다.

## 선택 가이드: 뮤텍스 vs 세마포어

- **뮤텍스**: 오직 하나의 스레드만 공유 자원에 접근해야 하는 <b>상호 배제(Mutual Exclusion)</b>가 목적일 때 사용합니다.
  - 예시: 전역 변수 수정, 로그 파일 쓰기 등
- **세마포어**: 정해진 개수(N개)의 스레드가 공유 자원에 동시에 접근할 수 있도록 허용하는 **자원 개수 관리**가 목적일 때 사용합니다.
  - 예시: 데이터베이스 연결 풀 관리, 동시에 파일을 다운로드하는 스레드 수 제한 등

## 관련 동기화 기법: 스핀락(Spinlock)

스핀락은 뮤텍스와 같이 임계 구역을 보호하는 동기화 기법이지만, 락을 기다리는 방식에서 근본적인 차이가 있습니다.

### 동작 방식: Busy-Waiting
-   뮤텍스는 락을 기다리는 동안 스레드를 **휴면(Sleep) 상태**로 전환하여 CPU를 다른 스레드에 양보합니다. (컨텍스트 스위치 발생)
-   반면 <b>스핀락(Spinlock)</b>은 락이 풀릴 때까지 CPU를 점유한 채로, 루프를 돌며 락 상태를 반복적으로 확인합니다. 이를 **Busy-Waiting**이라고 합니다.
    > **Busy-Waiting**: 스레드가 휴면하지 않고, CPU를 계속 사용하면서 조건이 만족될 때까지 반복적으로 확인하는 방식입니다. 아래와 같은 코드를 생각할 수 있습니다.
    > ```c
    > while (lock_is_taken)
    > { 
    >     /* do nothing and check again */ 
    > }
    > ```

### 스핀락은 언제 사용하는가?
스핀락은 다음과 같은 매우 제한적인 조건에서만 뮤텍스보다 효율적입니다.

1.  **임계 구역에서의 작업이 매우 짧을 때**: 락을 점유하는 시간이 컨텍스트 스위치에 드는 비용(스레드를 재우고 깨우는 시간)보다도 짧다고 예상될 때 유용합니다. 그렇지 않으면 CPU 시간만 낭비하게 됩니다.
2.  **멀티코어/멀티프로세서 환경일 때**: 스핀락이 의미가 있으려면, 락을 기다리는(spinning) 스레드가 동작하는 동안 다른 코어에서 락을 점유한 스레드가 실행되어 락을 해제할 수 있어야 합니다. 싱글코어 시스템에서는 스핀락이 돌기 시작하면 다른 스레드가 실행될 수 없으므로 사실상 시스템 전체가 멈추게 됩니다.

### 주요 장단점
-   **장점**: 컨텍스트 스위칭이 없으므로, 락을 짧게 점유하는 상황에서는 뮤텍스보다 훨씬 빠른 응답 속도를 보입니다.
-   **단점**: 락을 기다리는 시간이 조금이라도 길어지면 CPU를 극심하게 낭비합니다. 또한, 우선순위가 다른 스레드 간의 스핀락은 **우선순위 역전(Priority Inversion)** 문제를 일으켜 시스템을 교착 상태에 빠뜨릴 수 있습니다.
    > **우선순위 역전 해결책**: 이 문제를 해결하기 위해 일부 실시간 운영체제(RTOS)는 다음과 같은 프로토콜을 제공합니다.
        > - **우선순위 상속 (Priority Inheritance)**: 낮은 우선순위의 스레드가 높은 우선순위의 스레드가 기다리는 락을 점유하고 있을 경우, 일시적으로 낮은 우선순위 스레드의 우선순위를 높여주어 락을 빨리 해제하도록 만드는 **사후 대응적** 기법입니다.<br>
        > - **우선순위 실링 (Priority Ceiling)**: 각 락에 대해, 그 락을 사용할 수 있는 스레드 중 가장 높은 우선순위를 미리 '실링'으로 지정해두는 **사전 예방적** 기법입니다. 어떤 스레드든 해당 락을 획득하면, 자신의 우선순위가 즉시 이 '실링' 값으로 올라갑니다. 이는 마치 "이 자원은 '팀장'급 중요도를 가지니, 사용하는 동안에는 '사원'이라도 '팀장' 대우를 받는다"는 규칙을 두어, 어중간한 우선순위의 다른 작업이 끼어들지 못하게 하여 우선순위 역전 상황 자체를 원천적으로 방지하는 것과 같습니다.

이러한 특성 때문에 스핀락은 일반적인 응용 프로그램보다는 운영체제 커널 내부와 같이, 실행 환경이 엄격하게 제어되고 락의 점유 시간이 극도로 짧은 곳에서 주로 사용됩니다.

## 주의할 점: 데드락 (Deadlock)
뮤텍스나 세마포어를 잘못 사용하면 데드락이 발생할 수 있습니다. 예를 들어, 두 스레드가 서로 상대방이 점유한 리소스의 락을 기다리는 상황이 생기면 교착 상태에 빠질 수 있습니다.

### 데드락 예방 전략
-   **락 획득 순서 고정**: 모든 스레드가 동일한 순서로 락을 획득하도록 강제합니다.
-   **타임아웃 설정**: 락을 획득하기 위해 대기하는 최대 시간을 설정하고, 시간이 초과되면 락 획득을 포기하고 다른 작업을 수행하도록 합니다.

### 데드락 탐지 및 회복
예방 외에도, 시스템은 데드락 발생을 허용하되 이를 탐지하고 회복하는 전략을 사용할 수 있습니다. 예를 들어, <b>자원 할당 그래프(Resource Allocation Graph)</b>를 주기적으로 분석하여 사이클(순환 대기)이 생겼는지 확인하고, 데드락이 탐지되면 관련 스레드 중 하나를 강제 종료하거나, 점유한 자원을 선점(Preempt)하여 데드락 상태를 해소합니다.
> 자원 할당 그래프 기반의 탐지 알고리즘은 일반적으로 관련된 프로세스와 자원의 수(n)에 대해 O(n²) 이상의 시간 복잡도를 가질 수 있습니다. 이 때문에 데드락 발생 빈도가 낮고 성능이 매우 중요한 실시간 시스템 등에서는 탐지/회복 전략보다 예방 또는 회피 전략이 더 선호됩니다.

## 실무 적용 시 고려사항

이론을 아는 것과 실제 코드에 올바르게 적용하는 것은 다른 차원의 문제입니다. 실무에서 동기화 도구를 사용할 때 흔히 겪는 문제와 팁은 다음과 같습니다.

### 1. 락 해제를 잊지 마세요: RAII 패턴의 활용
`lock()`을 호출한 뒤, 함수 중간에서 예외가 발생하거나 조건문 때문에 `return` 되어 `unlock()`이 호출되지 않으면 해당 락은 영원히 풀리지 않아 시스템 전체가 멈출 수 있습니다.

> **실무 Tip:** C++에서는 이런 실수를 원천적으로 방지하기 위해 **RAII(Resource Acquisition Is Initialization)** 패턴을 활용한 `std::scoped_lock`이나 `std::lock_guard`를 사용하는 것이 표준적인 방법입니다. 이 클래스들은 객체가 생성될 때 자동으로 `lock()`을 호출하고, 해당 코드 블록(scope)을 벗어날 때 소멸자에서 자동으로 `unlock()`을 호출해줍니다.
> ```cpp
> // C++ 예시
> std::mutex mtx;
> void safe_function()
> {
>     // 이 함수 블록이 시작될 때 mtx.lock()이 호출됨
>     std::scoped_lock lock(mtx); 
>     
>     // ... 임계 구역 코드 ...
>     // 함수가 여기서 return 되거나 예외가 발생해도
>     // lock 객체가 소멸되면서 mtx.unlock()이 자동으로 보장됨
> }
> ```

### 2. 락의 범위(Granularity) 조절
동기화 코드의 성능은 락으로 보호하는 코드의 범위에 크게 좌우됩니다.

-   **너무 넓은 범위의 락 (Coarse-grained Lock):** 필요 이상으로 많은 코드 범위를 하나의 락으로 감싸면, 여러 스레드가 동시에 실행될 수 있는 기회가 줄어들어 병렬성이 저하되고 프로그램 성능이 떨어집니다.
-   **너무 좁은 범위의 락 (Fine-grained Lock):** 락을 너무 잘게 쪼개면, 락을 여러 번 획득하고 해제하는 오버헤드가 커지거나, 보호해야 할 모든 코드를 감싸지 못해 미묘한 경쟁 조건을 유발할 수 있습니다.

> **실무 Tip:** 성능과 안정성 사이의 균형을 맞추는 '적절한 락의 범위'를 찾는 것이 중요하며, 이는 실무에서 많은 고민과 테스트가 필요한 부분입니다.

### 3. 흔한 데드락 시나리오: 락 순서 불일치
가장 흔한 데드락 시나리오는 두 개 이상의 스레드가 여러 개의 락을 서로 **반대 순서**로 획득하려고 할 때 발생합니다.

-   **스레드 1**: `lock(A);` -> `lock(B);`
-   **스레드 2**: `lock(B);` -> `lock(A);`

만약 스레드 1이 A를, 스레드 2가 B를 동시에 획득하면, 스레드 1은 B를 기다리고 스레드 2는 A를 기다리며 영원히 서로를 기다리는 데드락에 빠집니다.

> **실무 Tip:** 여러 개의 락을 사용해야 한다면, 시스템 전체에서 모든 스레드가 **항상 동일한 순서로 락을 획득하도록 규칙을 강제**하는 것이 데드락을 예방하는 가장 간단하고 효과적인 방법입니다.

## 더 나아가기: 락 없는(Lock-Free) 동기화

지금까지 논의한 모든 기법은 '락(Lock)'을 사용합니다. 하지만 극도의 성능을 추구하는 시스템에서는 락 자체가 성능 저하의 원인이 되거나 데드락 같은 문제를 유발할 수 있습니다. 이를 해결하기 위해 락을 전혀 사용하지 않는 **락 프리(Lock-Free)** 프로그래밍 기법이 존재합니다.

- **핵심 아이디어**: 락 대신, 하드웨어 수준에서 지원하는 <b>원자적 연산(Atomic Operation)</b>을 사용하여 데이터의 일관성을 유지합니다.
- **원자적 연산**: `Compare-And-Swap(CAS)`과 같이, '값을 읽고-비교하고-쓰는' 전체 과정을 누구에게도 방해받지 않는 단 하나의 명령어로 처리하는 기능입니다.
- **장점**: 락으로 인한 데드락, 우선순위 역전 문제가 원천적으로 발생하지 않습니다. 경합이 심한 상황에서도 스레드들이 멈추지 않고 계속 작업을 시도하므로 시스템 전체의 처리량이 향상될 수 있습니다.
- **단점**: 구현이 매우 복잡하고 어렵습니다. 미묘한 버그가 발생하기 쉬우며, 메모리 모델에 대한 깊은 이해가 필요합니다. `ABA 문제`와 같은 락 프리 프로그래밍 고유의 난제들도 존재합니다.
    > **ABA 문제란?** CAS(Compare-And-Swap) 연산을 사용할 때 발생하는 문제입니다. 스레드 1이 특정 메모리의 값이 'A'인 것을 확인하고 값을 바꾸려던 참에 잠시 멈췄다고 가정합시다. 그 사이에 다른 스레드가 끼어들어 해당 메모리의 값을 'A'에서 'B'로, 다시 'A'로 되돌려 놓으면, 나중에 깨어난 스레드 1은 값이 변하지 않았다고 착각하고 중간에 일어난 일을 알지 못한 채 잘못된 연산을 수행하게 됩니다. 이처럼 값이 A -> B -> A로 변해 CAS 연산을 속이는 현상을 ABA 문제라고 합니다.

### Lock-Free vs. Wait-Free: 보장 수준의 차이

락-프리라고 해서 모든 문제가 해결되는 것은 아니며, 보장 수준에 따라 단계가 나뉩니다.

-   **락-프리 (Lock-Free):** 시스템 전체의 진행을 보장합니다. 즉, 여러 스레드가 동시에 작업을 시도할 때, 적어도 하나의 스레드는 반드시 작업을 성공하고 앞으로 나아갑니다. 하지만 특정 스레드가 계속해서 다른 스레드에 밀려 작업을 완료하지 못하는 <b>기아 상태(Starvation)</b>가 발생할 가능성은 있습니다.

-   **웨이트-프리 (Wait-Free):** 락-프리보다 훨씬 강력한 보장 수준을 제공합니다. **모든 스레드**가 유한한 횟수의 시도 안에 자신의 작업을 반드시 완료하는 것을 보장합니다. 기아 상태가 원천적으로 발생하지 않습니다.

> **어느 것이 더 좋은가?**
> 이론적으로는 모든 스레드의 성공을 보장하는 웨이트-프리가 더 우수합니다. 하지만 이를 위한 알고리즘은 매우 복잡하고, 평균적인 처리량(Throughput)은 오히려 더 간단한 락-프리 알고리즘보다 낮은 경우가 많습니다. 따라서 모든 작업의 완료가 반드시 보장되어야 하는 하드 리얼타임 시스템 등이 아니라면, 실무적으로는 락-프리 수준에서 타협하는 경우가 대부분입니다.

이러한 락 프리 기법은 일반적인 응용 프로그램보다는 고성능 라이브러리, OS 커널, 동시성 자료구조(Concurrent Data Structure) 등을 개발할 때 사용되는 고급 기법입니다.
