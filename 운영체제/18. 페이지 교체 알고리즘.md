# 페이지 교체 알고리즘

## 1. 프레임 할당 (Frame Allocation)

페이지 교체 알고리즘을 이해하기에 앞서, 운영체제가 각 프로세스에 메모리 공간(페이지 프레임)을 어떻게 분배하는지 알아야 합니다. **프레임 할당**은 각 프로세스에 '몇 개의 페이지 프레임을 할당할 것인가'를 결정하는 정책입니다.

프로세스가 실행되기 위해서는 최소한의 프레임이 필요하며, 할당된 프레임의 수는 시스템 성능에 직접적인 영향을 줍니다.

*   **너무 적은 프레임 할당**: 페이지 폴트가 빈번하게 발생하여 CPU가 대부분의 시간을 페이지를 디스크에서 읽어오는 데 사용하게 됩니다. 이로 인해 CPU 이용률이 급격히 떨어지는 **스레싱(Thrashing)** 현상이 발생할 수 있습니다.
*   **너무 많은 프레임 할당**: 메모리가 낭비되고, 다중 프로그래밍의 정도(동시에 실행 가능한 프로세스의 수)가 감소합니다.

### 프레임 할당 전략

주요 프레임 할당 전략은 다음과 같습니다.

*   **균등 할당 (Equal Allocation):**
    *   가장 간단한 방식으로, 모든 프로세스에 동일한 수의 프레임을 할당합니다.
    *   **장점:** 구현이 간단합니다.
    *   **단점:** 프로세스의 크기나 특성을 고려하지 않아 비효율적일 수 있습니다. (작은 프로세스는 메모리를 낭비하고, 큰 프로세스는 프레임이 부족할 수 있음)
*   **비례 할당 (Proportional Allocation):**
    *   프로세스의 크기에 비례하여 프레임을 할당합니다.
    *   **장점:** 균등 할당보다 합리적이고 효율적입니다.
    *   **단점:** 프로세스의 우선순위나 실행 특성을 고려하지는 않습니다.
*   **우선순위 할당 (Priority Allocation):**
    *   프로세스의 우선순위에 따라 할당할 프레임 수를 결정합니다. 우선순위가 높은 프로세스에 더 많은 프레임을 할당하여 더 원활하게 실행되도록 돕습니다.

이러한 할당 전략에 따라 프로세스가 프레임을 모두 사용하게 되면, 그때부터 **페이지 교체 알고리즘**이 동작하여 새로운 페이지를 위한 공간을 마련하게 됩니다.

---

## 2. 페이지 교체 알고리즘이란?

운영체제가 **가상 메모리**를 관리할 때, 메인 메모리(RAM)에 공간이 부족해지면 어떤 **페이지**를 디스크(스왑 공간)로 내보낼지 결정하는 규칙입니다. 페이지 교체는 단순히 페이지 부재가 발생했을 때만 일어나는 것이 아니라, 메모리가 가득 찼을 때 어떤 페이지를 비울지 결정하는 **정책(Policy)** 그 자체를 의미하며, 이 결정에 따라 시스템 전체의 성능이 크게 달라질 수 있습니다.

> **- 페이지(Page)란?** 가상 메모리를 사용하는 시스템에서 메모리를 관리하는 고정 크기의 기본 단위입니다.</br>
> **- 페이지 부재(Page Fault)란?** CPU가 접근하려는 페이지가 현재 메인 메모리에 없는 상황을 말합니다. 이때 운영체제는 디스크에서 해당 페이지를 메모리로 가져와야 하며, 이 과정에서 시간 지연이 발생합니다.

## 3. 주요 알고리즘 종류와 특징

### 가. 최적 (OPT, Optimal) 페이지 교체

앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는, 이론상 가장 완벽한 알고리즘입니다.

- **핵심 아이디어:** 미래의 페이지 접근 순서를 모두 알고 있다고 가정합니다.
- **장점:**
  - 가장 적은 페이지 부재를 보장하는 **이론적 최적 성능**을 제공하며, 다른 알고리즘의 성능을 평가하는 기준으로 사용됩니다.
- **단점:**
  - 실제 시스템에서는 미래의 접근을 예측할 수 없으므로 **구현이 불가능합니다.**

### 나. FIFO (First-In, First-Out)

가장 먼저 메모리에 들어온 페이지를 가장 먼저 내보내는 가장 단순한 방식입니다. (주로 Queue로 구현)

- **장점:**
  - 구현이 매우 간단하고 쉽습니다.
- **단점:**
  - 페이지의 최근 사용 여부나 사용 빈도를 고려하지 않아 비효율적일 수 있습니다.
  - **벨레이디의 모순(Belady's Anomaly)** 현상이 발생할 수 있습니다.
    > **- 벨레이디의 모순이란?** 메모리 프레임 수를 늘려주었음에도 불구하고 오히려 페이지 부재가 더 많이 발생하는 비정상적인 현상입니다. 예를 들어, 특정 페이지 참조 순서에서는 메모리 프레임이 3개일 때보다 4개일 때 페이지 부재가 오히려 더 많이 발생할 수 있습니다.

### 다. LRU (Least Recently Used)

가장 오랫동안 사용되지 않은 페이지를 교체 대상으로 선택합니다. "최근에 사용된 페이지는 앞으로도 사용될 가능성이 높다"는 **참조의 지역성(Locality of Reference)** 원리에 기반합니다.

- **장점:**
  - 실제 프로그램의 동작 방식과 유사하여 OPT에 근접하는 좋은 성능을 보입니다.
- **단점:**
  - 모든 페이지의 접근 순서를 추적해야 하므로 구현이 복잡하고 시스템에 상당한 **오버헤드**를 유발합니다. (일반적으로 Doubly Linked List와 Hash Map을 조합하여 구현하지만, 오버헤드 때문에 최근에는 하드웨어 지원이나 Clock 같은 근사 알고리즘이 더 실용적으로 사용됩니다.)

### 라. LFU (Least Frequently Used)

사용 빈도가 가장 낮은 페이지를 교체하는 방식입니다. "자주 사용되지 않는 페이지는 앞으로도 사용되지 않을 가능성이 높다"는 가정에 기반합니다. (주로 Heap으로 구현)

- **장점:**
  - 장기적인 관점에서 잘 사용되지 않는 페이지를 교체하는 데 효과적입니다.
- **단점:**
  - 과거에 집중적으로 사용되어 빈도수가 높은 페이지가, 최근에 더 자주 사용되는 페이지보다 우선순위가 높아져 메모리를 불필요하게 차지하는 경우가 생깁니다. (이 문제는 시간에 따라 가중치를 두어 오래된 기록의 빈도수를 점차 감소시키는 'Aging LFU' 같은 변형으로 완화할 수 있습니다.)
  - 사용 빈도를 계산하고 추적하는 데 오버헤드가 발생합니다.

### 마. Clock 알고리즘 (Second-Chance Algorithm)

LRU의 장점을 살리면서도 높은 오버헤드를 피하기 위해 고안된, **LRU의 근사(Approximation) 알고리즘**입니다.

- **핵심 아이디어:** 각 페이지에 <b>참조 비트(Reference Bit)</b>라는 1비트짜리 기회를 줍니다. (0: 기회 없음, 1: 기회 있음)
- **동작 방식:**
  1. 원형 큐(Circular Queue) 형태로 페이지들을 관리하며 포인터(시곗바늘)가 특정 페이지를 가리킵니다.
  2. 페이지 부재가 발생하면, 포인터가 다음 페이지로 이동합니다.
  3. 가리키는 페이지의 참조 비트가 `1`이면, 기회를 한 번 주고 비트를 `0`으로 바꾼 뒤 포인터를 다음으로 넘깁니다. (Second Chance)
  4. 참조 비트가 `0`이면, 그 페이지를 교체하고 새로운 페이지를 넣습니다.
- **장점:**
  - LRU와 비슷한 성능을 내면서도, 참조 비트 하나만 확인하면 되므로 구현이 간단하고 오버헤드가 훨씬 적습니다.
- **단점:**
  - 참조 비트를 확인하고 변경하는 데 하드웨어(참조 비트) 지원이 있으면 더 효율적입니다. (참조 비트는 메모리 관리 장치(MMU)에 의해 자동으로 설정되는 경우가 많지만, 운영체제가 소프트웨어적으로 관리하는 것도 가능합니다.)

## 4. 알고리즘 비교

| 알고리즘 | 핵심 아이디어 | 장점 | 단점 |
| --- | --- | --- | --- |
| **OPT** | 미래에 가장 늦게 쓰일 페이지 교체 | 최적의 성능 (기준점) | **구현 불가능** |
| **FIFO** | 가장 먼저 들어온 페이지 교체 | 구현 매우 간단 | 성능 예측 어려움, 벨레이디 모순 |
| **LRU** | 가장 오래전에 사용된 페이지 교체 | 안정적인 고성능 | 구현 복잡, 오버헤드 큼 |
| **LFU** | 사용 빈도가 가장 낮은 페이지 교체 | 장기적 패턴에 유리 | 단기적 비효율, 오버헤드 발생 |
| **Clock** | 참조 비트로 기회를 주는 LRU 근사 | **적은 오버헤드, LRU와 유사 성능** | 하드웨어 지원 시 효율적 |

## 5. 결론 및 심화

페이지 교체 알고리즘은 **성능, 구현 난이도, 오버헤드** 사이의 균형을 맞추는 것이 중요합니다.

- **혼합형 교체 전략:** 현대 운영체제에서는 단일 알고리즘보다 여러 전략을 결합한 혼합형 알고리즘을 사용하는 경우가 많습니다. 예를 들어, Linux는 Clock 알고리즘의 변형인 **Clock-Pro**를, Windows는 **WSClock** 같은 알고리즘을 사용합니다. (WSClock은 페이지의 <b>수정 여부(Dirty Bit)</b>까지 함께 고려하여, 변경되지 않은 페이지를 우선 교체함으로써 디스크 쓰기 비용까지 줄이는 더 발전된 방식입니다.)

- **메모리 계층 구조와의 연관성:** 페이지 교체 알고리즘의 기본 아이디어(LRU, LFU 등)는 CPU 캐시의 교체 정책과도 매우 유사합니다. 이는 두 기술 모두 '참조의 지역성' 원리를 활용하여 한정된 고속 저장 공간을 효율적으로 사용하려는 동일한 목표를 가지기 때문입니다. 따라서 이 개념은 메모리 계층 구조 전체를 이해하는 데 도움이 됩니다.

- **시스템 특성에 따른 선택:** - **게임 개발 관점에서의 응용:**
    - **문제점:** 오픈 월드 게임처럼 방대한 데이터를 다루는 경우, 플레이어의 움직임에 따라 어떤 데이터를 메모리에 올리고 내릴지 효율적으로 결정해야 합니다. 운영체제의 페이지 교체 알고리즘에만 의존하면, 예측하지 못한 페이지 폴트로 인해 게임이 끊기는 현상(스터터링, Stuttering)이 발생할 수 있습니다.
        - **해결책 (데이터 스트리밍):** 게임 엔진은 페이지 교체 알고리즘의 동작을 보완하기 위해 <b>데이터 스트리밍(Data Streaming)</b>이라는 상위 레벨의 관리 기법을 사용합니다.
        - **미리 로딩 (Pre-fetching):** 플레이어가 특정 지역으로 이동할 것을 예측하여, 필요한 맵 데이터, 텍스처, 사운드 등을 미리 메모리에 로드합니다. 이는 필요한 시점에 페이지 폴트가 발생할 확률을 크게 낮춥니다. 물론, 예측이 빗나가면 불필요한 디스크 I/O와 메모리 낭비를 초래할 수도 있어 정교한 예측 알고리즘이 필요합니다.
        - **데이터 배출 (Eviction):** 플레이어에게서 멀어져 더 이상 필요 없어진 데이터를 메모리에서 해제하도록 표시합니다. 이는 운영체제가 페이지를 교체할 때 어떤 페이지를 내보낼지 결정하는 데 중요한 힌트가 됩니다. 실제 구현에서는 플랫폼별 API를 통해 힌트를 전달합니다. 예를 들어, Windows에서는 `OfferVirtualMemory` 같은 API를 사용해 "지금 당장 필요하지 않으니 시스템이 메모리가 부족하면 이 메모리를 가져가도 좋다"고 알려줄 수 있습니다. 언리얼 엔진과 같은 게임 엔진은 자체적인 스트리밍 시스템을 통해 어떤 애셋(맵, 텍스처 등)이 덜 중요한지 판단하고, 내부적으로 이러한 OS API를 호출하여 메모리 관리를 최적화합니다.
    - **C++에서의 데이터 지역성 최적화:** 페이지 교체는 아니지만, 관련된 최적화로 C++ 코드 수준에서 데이터 접근 패턴을 개선하는 것이 있습니다. 예를 들어, `std::vector`처럼 연속적인 메모리 공간을 사용하는 데이터 구조는 관련 데이터들을 동일한 페이지(또는 인접한 페이지)에 모아줍니다. 이렇게 데이터를 순차적으로 접근하면 CPU 캐시 히트율이 높아질 뿐만 아니라, 페이지 폴트 발생도 줄어들어 운영체제의 메모리 관리 시스템과 시너지를 냅니다.
    - **결론:** 즉, 게임 엔진은 운영체제의 페이지 교체 알고리즘이 최적의 결정을 내릴 수 있도록, 데이터의 중요도와 접근 패턴을 미리 알려주고 최적화하는 역할을 합니다. 이를 통해 페이지 폴트를 최소화하고 부드러운 게임 경험을 제공합니다.