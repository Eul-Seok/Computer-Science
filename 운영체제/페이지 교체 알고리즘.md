# 페이지 교체 알고리즘 (Page Replacement Algorithm)

## 1. 페이지 교체 알고리즘이란?

운영체제가 **가상 메모리**를 관리할 때, 메인 메모리(RAM)에 공간이 부족해지면 어떤 **페이지**를 디스크(스왑 공간)로 내보낼지 결정하는 규칙입니다. 페이지 교체는 단순히 페이지 부재가 발생했을 때만 일어나는 것이 아니라, 메모리가 가득 찼을 때 어떤 페이지를 비울지 결정하는 **정책(Policy)** 그 자체를 의미하며, 이 결정에 따라 시스템 전체의 성능이 크게 달라질 수 있습니다.

> **- 페이지(Page)란?** 가상 메모리를 사용하는 시스템에서 메모리를 관리하는 고정 크기의 기본 단위입니다.</br>
> **- 페이지 부재(Page Fault)란?** CPU가 접근하려는 페이지가 현재 메인 메모리에 없는 상황을 말합니다. 이때 운영체제는 디스크에서 해당 페이지를 메모리로 가져와야 하며, 이 과정에서 시간 지연이 발생합니다.

## 2. 주요 알고리즘 종류와 특징

### 가. 최적 (OPT, Optimal) 페이지 교체

앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는, 이론상 가장 완벽한 알고리즘입니다.

- **핵심 아이디어:** 미래의 페이지 접근 순서를 모두 알고 있다고 가정합니다.
- **장점:**
  - 가장 적은 페이지 부재를 보장하는 **이론적 최적 성능**을 제공하며, 다른 알고리즘의 성능을 평가하는 기준으로 사용됩니다.
- **단점:**
  - 실제 시스템에서는 미래의 접근을 예측할 수 없으므로 **구현이 불가능합니다.**

### 나. FIFO (First-In, First-Out)

가장 먼저 메모리에 들어온 페이지를 가장 먼저 내보내는 가장 단순한 방식입니다. (주로 Queue로 구현)

- **장점:**
  - 구현이 매우 간단하고 쉽습니다.
- **단점:**
  - 페이지의 최근 사용 여부나 사용 빈도를 고려하지 않아 비효율적일 수 있습니다.
  - **벨레이디의 모순(Belady's Anomaly)** 현상이 발생할 수 있습니다.
    > **- 벨레이디의 모순이란?** 메모리 프레임 수를 늘려주었음에도 불구하고 오히려 페이지 부재가 더 많이 발생하는 비정상적인 현상입니다. 예를 들어, 특정 페이지 참조 순서에서는 메모리 프레임이 3개일 때보다 4개일 때 페이지 부재가 오히려 더 많이 발생할 수 있습니다.

### 다. LRU (Least Recently Used)

가장 오랫동안 사용되지 않은 페이지를 교체 대상으로 선택합니다. "최근에 사용된 페이지는 앞으로도 사용될 가능성이 높다"는 **참조의 지역성(Locality of Reference)** 원리에 기반합니다.

- **장점:**
  - 실제 프로그램의 동작 방식과 유사하여 OPT에 근접하는 좋은 성능을 보입니다.
- **단점:**
  - 모든 페이지의 접근 순서를 추적해야 하므로 구현이 복잡하고 시스템에 상당한 **오버헤드**를 유발합니다. (일반적으로 Doubly Linked List와 Hash Map을 조합하여 구현하지만, 오버헤드 때문에 최근에는 하드웨어 지원이나 Clock 같은 근사 알고리즘이 더 실용적으로 사용됩니다.)

### 라. LFU (Least Frequently Used)

사용 빈도가 가장 낮은 페이지를 교체하는 방식입니다. "자주 사용되지 않는 페이지는 앞으로도 사용되지 않을 가능성이 높다"는 가정에 기반합니다. (주로 Heap으로 구현)

- **장점:**
  - 장기적인 관점에서 잘 사용되지 않는 페이지를 교체하는 데 효과적입니다.
- **단점:**
  - 과거에 집중적으로 사용되어 빈도수가 높은 페이지가, 최근에 더 자주 사용되는 페이지보다 우선순위가 높아져 메모리를 불필요하게 차지하는 경우가 생깁니다. (이 문제는 시간에 따라 가중치를 두어 오래된 기록의 빈도수를 점차 감소시키는 'Aging LFU' 같은 변형으로 완화할 수 있습니다.)
  - 사용 빈도를 계산하고 추적하는 데 오버헤드가 발생합니다.

### 마. Clock 알고리즘 (Second-Chance Algorithm)

LRU의 장점을 살리면서도 높은 오버헤드를 피하기 위해 고안된, **LRU의 근사(Approximation) 알고리즘**입니다.

- **핵심 아이디어:** 각 페이지에 <b>참조 비트(Reference Bit)</b>라는 1비트짜리 기회를 줍니다. (0: 기회 없음, 1: 기회 있음)
- **동작 방식:**
  1. 원형 큐(Circular Queue) 형태로 페이지들을 관리하며 포인터(시곗바늘)가 특정 페이지를 가리킵니다.
  2. 페이지 부재가 발생하면, 포인터가 다음 페이지로 이동합니다.
  3. 가리키는 페이지의 참조 비트가 `1`이면, 기회를 한 번 주고 비트를 `0`으로 바꾼 뒤 포인터를 다음으로 넘깁니다. (Second Chance)
  4. 참조 비트가 `0`이면, 그 페이지를 교체하고 새로운 페이지를 넣습니다.
- **장점:**
  - LRU와 비슷한 성능을 내면서도, 참조 비트 하나만 확인하면 되므로 구현이 간단하고 오버헤드가 훨씬 적습니다.
- **단점:**
  - 참조 비트를 확인하고 변경하는 데 하드웨어(참조 비트) 지원이 있으면 더 효율적입니다. (참조 비트는 메모리 관리 장치(MMU)에 의해 자동으로 설정되는 경우가 많지만, 운영체제가 소프트웨어적으로 관리하는 것도 가능합니다.)

## 3. 알고리즘 비교

| 알고리즘 | 핵심 아이디어 | 장점 | 단점 |
| --- | --- | --- | --- |
| **OPT** | 미래에 가장 늦게 쓰일 페이지 교체 | 최적의 성능 (기준점) | **구현 불가능** |
| **FIFO** | 가장 먼저 들어온 페이지 교체 | 구현 매우 간단 | 성능 예측 어려움, 벨레이디 모순 |
| **LRU** | 가장 오래전에 사용된 페이지 교체 | 안정적인 고성능 | 구현 복잡, 오버헤드 큼 |
| **LFU** | 사용 빈도가 가장 낮은 페이지 교체 | 장기적 패턴에 유리 | 단기적 비효율, 오버헤드 발생 |
| **Clock** | 참조 비트로 기회를 주는 LRU 근사 | **적은 오버헤드, LRU와 유사 성능** | 하드웨어 지원 시 효율적 |

## 4. 결론 및 심화

페이지 교체 알고리즘은 **성능, 구현 난이도, 오버헤드** 사이의 균형을 맞추는 것이 중요합니다.

- **혼합형 교체 전략:** 현대 운영체제에서는 단일 알고리즘보다 여러 전략을 결합한 혼합형 알고리즘을 사용하는 경우가 많습니다. 예를 들어, Linux는 Clock 알고리즘의 변형인 **Clock-Pro**를, Windows는 **WSClock** 같은 알고리즘을 사용합니다. (WSClock은 페이지의 <b>수정 여부(Dirty Bit)</b>까지 함께 고려하여, 변경되지 않은 페이지를 우선 교체함으로써 디스크 쓰기 비용까지 줄이는 더 발전된 방식입니다.)

- **시스템 특성에 따른 선택:** 페이지 교체 알고리즘은 단순히 이론적인 성능뿐만 아니라, 시스템의 응답 시간, 예측 가능성, 주된 메모리 접근 패턴(예: 데이터베이스 서버, 웹 서버 등)까지 종합적으로 고려하여 선택해야 합니다. 따라서 시스템의 목적에 따라 최적의 알고리즘은 달라질 수 있습니다.

- **메모리 계층 구조와의 연관성:** 페이지 교체 알고리즘의 기본 아이디어(LRU, LFU 등)는 CPU 캐시의 교체 정책과도 매우 유사합니다. 이는 두 기술 모두 '참조의 지역성' 원리를 활용하여 한정된 고속 저장 공간을 효율적으로 사용하려는 동일한 목표를 가지기 때문입니다. 따라서 이 개념은 메모리 계층 구조 전체를 이해하는 데 도움이 됩니다.